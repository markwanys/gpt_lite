{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31343,"status":"ok","timestamp":1690354197019,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"do7_XncvZfTD","outputId":"efce0b84-3ca0-45ef-a850-c3ea4fdfd21b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":690,"status":"ok","timestamp":1690354197706,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"pW7lYfRFZfTE"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Workspaces/gpt_lite')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5682,"status":"ok","timestamp":1690354203385,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"uM1d98w9hPDI"},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","from utils import *"]},{"cell_type":"markdown","metadata":{"id":"T3oR3T89hPDG"},"source":["# <b> GPT-Lite"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":721,"status":"ok","timestamp":1690354204103,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"-BCeFhcNhPDJ","outputId":"8e3c88c1-fe68-44a1-e9de-da8c0393c466"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Device:  cuda:0\n"]}],"source":["# Set seed for reproducibility.\n","seed = 1\n","set_seed(seed)\n","\n","# Load GPU.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('Loaded Device: ', device)"]},{"cell_type":"markdown","metadata":{"id":"isN6cv1wkKTW"},"source":["### <b> Explore Input"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":681,"status":"ok","timestamp":1690354204783,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"f1AHAVaHKkWm"},"outputs":[],"source":["# Explore input\n","with open('input_seuss.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1690354204784,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"RDbtE2MI_kk2","outputId":"06dfca60-7adb-4c89-aee3-668ebc493f07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of tokens: 30504\n"]}],"source":["print(f'Total number of tokens: {len(text)}')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1690354204784,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"xo-NDYfy_kk2","outputId":"e39aacbb-1b5e-4410-e125-a8ae0831cadb"},"outputs":[{"output_type":"stream","name":"stdout","text":["The Cat in the Hat\n","\n","By Dr. Seuss\n","\n","The sun did not shine.\n","It was too wet to play.\n","So we sat in the house\n","All that cold, cold, wet day.\n","\n","I sat there with Sally.\n","We sat there, we two.\n","And I said, \"How I wish\n","We had something to do!\"\n","\n","Too wet to go out\n","And too cold to play ball.\n","So we sat in the house.\n","We did nothing at all.\n","\n","So all we could do was to\n","\n","Sit!\n","Sit!\n","Sit!\n","Sit!\n","\n","And we did not like it.\n","Not one little bit.\n","\n","BUMP!\n","\n","And then\n","something went BUMP!\n","How that bump made us jump!\n","\n","We looked!\n","Then w\n"]}],"source":["print(text[:500])"]},{"cell_type":"markdown","metadata":{"id":"WR_ieusZhPDK"},"source":["### <b> Hyperparameters"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690354204784,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"-cj1hL5nhPDK"},"outputs":[],"source":["# Define data loading parameters.\n","batch_size = 64 # 64 # 16\n","context_size = 256 # 256 # 32\n","max_iterations = 5000\n","eval_interval = 500 # 500 # 100\n","learning_rate = 3e-4 # 3e-4 # 1e-3\n","eval_iters = 200\n","n_embeddings = 384 # 384 # 64\n","n_heads = 6 # 6 # 4\n","n_layers = 6 # 6 # 4\n","dropout = 0.2 # 0.2 # 0.0\n","train_test_split = 0.9"]},{"cell_type":"markdown","metadata":{"id":"OlUIaptp_kk3"},"source":["### <b> Load Data"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690354204785,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"cYs-_KoY_kk4"},"outputs":[],"source":["vocab_size, encode, decode, train_data, val_data = data(text, train_test_split)"]},{"cell_type":"markdown","metadata":{"id":"YtNjnIrahPDP"},"source":["### <b> Initiate GPT"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5837,"status":"ok","timestamp":1690354210618,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"9ojSXwqFhPDP","outputId":"ec1b3f11-4cea-4cbb-d21b-b2331b2c5b42"},"outputs":[{"output_type":"stream","name":"stdout","text":["10.788929 M parameters\n"]}],"source":["# Initiate GPT.\n","model = BigramModel(vocab_size, n_embeddings, n_heads, n_layers, context_size, dropout, device)\n","model = model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"]},{"cell_type":"markdown","metadata":{"id":"72kBlS8okKTb"},"source":["### <b> Model Training"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3074503,"status":"ok","timestamp":1690357320884,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"f_4e5vwzhPDR","outputId":"acb799ce-7e4f-4f3e-ee39-901cbbc0ef87"},"outputs":[{"output_type":"stream","name":"stdout","text":["step 0: train loss 4.3583, val loss 4.3480\n","step 500: train loss 1.2170, val loss 2.2679\n","step 1000: train loss 0.1854, val loss 3.1624\n","step 1500: train loss 0.0743, val loss 3.8812\n","step 2000: train loss 0.0567, val loss 4.2883\n","step 2500: train loss 0.0497, val loss 4.5324\n","step 3000: train loss 0.0446, val loss 4.6826\n","step 3500: train loss 0.0424, val loss 4.7823\n","step 4000: train loss 0.0399, val loss 4.9905\n","step 4500: train loss 0.0386, val loss 5.0220\n","step 4999: train loss 0.0378, val loss 5.1313\n"]}],"source":["# Define loss function and optimizer.\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","# Train model and return results.\n","# Note: If early stopping is False then patience is not used.\n","model = train_model(\n","                        train_data, val_data,\n","                        batch_size = batch_size,\n","                        context_size = context_size,\n","                        max_iterations = max_iterations,\n","                        eval_interval = eval_interval,\n","                        learning_rate = learning_rate,\n","                        eval_iters = eval_iters,\n","                        n_embeddings = n_embeddings,\n","                        n_heads = n_heads,\n","                        n_layers = n_layers,\n","                        dropout = dropout,\n","                        train_test_split = train_test_split,\n","                        model = model,\n","                        optimizer = optimizer,\n","                        device = device\n","                        )\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":2738,"status":"error","timestamp":1690358229093,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"nLMC691RIZdo","outputId":"3c4f474c-3e84-40f6-9828-3b0a71ce8ba3"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-f6fbade08736>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_scripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_scripted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./save_files/seuss_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, f, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_save_for_lite_interpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: strides() called on an undefined Tensor"]}],"source":["torch.save(model.state_dict(), \"./save_files/seuss_state.pt\")\n","\n","# model_scripted = torch.jit.script(model)\n","# model_scripted.save('./save_files/seuss_model.pt')"]},{"cell_type":"markdown","metadata":{"id":"j9oUndFmkKTc"},"source":["### <b> Generate Text"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35224,"status":"ok","timestamp":1690357357310,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"vNdDRHk7dVc9","outputId":"46b9b682-e96e-4712-d3bd-18573182578c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","I can't say.\n","\n","Luke Luck likes duck likes lakes.\n","Luke Luck licks lakes.\n","Luck's duck licks lakes.\n","\n","Duck takes licks in lakes Luke Luke Luck likes.\n","Luke Luck takes licks in lakes duck likes.\n","\n","I can't blab such blibber blubber!\n","My tongue isn't make of rubber.\n","\n","Mr. Knox.  Now come now.  Come now.\n","You don't have to be so dumb now....\n","\n","Try to say this, Mr. Knox, please.....\n","\n","Through three cheese trees three free fleas flew.\n","While these fleas flew, freezy breeze blew.\n","Freezy brothereeze made these three trees' cheese freeze.\n","That's what made these three free fleas sneeze.\n","\n","Stop it!  Stop it!\n","That's enough, sir.\n","I say can't such sill stuff, sir.\n","\n","Very well, then, Mr. Knox, sir.\n","\n","Let's have a little talk about tweetle th beetles....\n","\n","What do you know about tweetle beetles?  Well....\n","\n","When tweetle beetles fight, \n","it's called a tweetle beetle battle.\n","\n","And they battle in a puddle, \n","it's a tweetle beetle puddle battle.\n","\n","AND So whe saw twee them cat in the him out,\n","Sall the say!\"\n","\n","\"The we the cat with a bow.\n","\n","\"I will pick up the hook.\n","You will see something new.\n","Two things. And I call them\n","Thing One and Thing Two.\n","These Things will not bite you.\n","They want to have fun.\"\n","Then, out of the box\n","Came Thing Two and Thing One!\n","And they ran to us fast!\n","They said, \"How do you do?\n","Would you like to shake hands\n","With Thing One and Thing Two?\"\n","\n","And Sally and I\n","Did not know what to do.\n","So we had to shake hands\n","With Thing One and Thing Two.\n","We shook their two hands.\n","But our fish said, \"No! No!\n","Those Things should not be\n","In this house! Make them go!\n","\"They should not be here\n","When your mother is not!\n","Put them out! Put the them out!\"\n","Said the fish in the pot.\n","\n","\"Have no fear, little fish,\"\n","Said the Cat in the Hat.\n","\"These Things are good Things.\"\n","And he gave them a pat.\n","\"They are tame. Oh, so tame!\n","They have come here to play.\n","They will give you some fun\n","On this weet, wet, wet, wet day.\"\n","\n","\"Now, here is a game that they like,\"\n","Said the cat.\n","\"They like to fly kites,\"\n","Said the Cat in the Hat\n","\n","\"No! Not in \n"]}],"source":["context = torch.zeros((1, 1), dtype=torch.long, device=device)\n","output = decode(model.generate(context, max_new_tokens=2000, context_size=context_size)[0].tolist())\n","print(output)\n","\n","with open('output_seuss.txt', 'w') as f:\n","    f.write(output)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1690357357311,"user":{"displayName":"Mark Wan","userId":"11243616124484774426"},"user_tz":-480},"id":"GgoiKXOWN65b"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"ff95278ca4fdd316eea1c7e2e5a88b898011bc9033677a5a869983a754e9d9b2"}}},"nbformat":4,"nbformat_minor":0}